{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthode applicable de façon totalement automatique:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons maintenant développer une fonction pouvant traiter de façon totalement automatique tout ce que l'on vient de faire. \n",
    "\n",
    "Les entrées de cette fonction sont:\n",
    "- Les deux datasets\n",
    "- Les noms respectifs des colonnes communes à ces deux datasets\n",
    "\n",
    "Les sorties de cette fonction sont: \n",
    "- Le Dataset avec toutes les données associées trouvées\n",
    "- Le Dataset contenant exclusivement les résultats trouvés lors de l'étape 2, qui sont donc moins 'sûrs', avec le score TF-IDF associé, ce qui permet de trier par ordre croissant de ce score et par conséquent de vérifier en premier les résultats les 'moins' certains. \n",
    "\n",
    "**Etapes nécessaires:**\n",
    "\n",
    "    1) \n",
    "\n",
    "\n",
    "\n",
    "Affichages de cette fonction:\n",
    "- Nombre d'associations trouvées à chaque étape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import unidecode\n",
    "\n",
    "#Necessary imports for tfidf and cosine similarity:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction à mettre en place:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la présente partie de ce notebook, nous allons développer des fonctions permettant de mettre en place une fonction globale mettant en place le rapprochement de deux datasets de façon automatique, tel qu'explicité en introduction de ce notebook.\n",
    "\n",
    "La plupart des fonctions developpées dans cette partie l'ont déjà été dans [ce notebook de travail](https://github.com/adrihans/musees_de_france_app/blob/master/Linking_datasets.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_string(string):\n",
    "    \"\"\"\n",
    "    function 'format_string' to transform a given string \n",
    "    \n",
    "    @Inputs : \n",
    "    -string, str\n",
    "    \n",
    "    @Outputs : \n",
    "    -string, str\n",
    "    \"\"\"\n",
    "    string=unidecode.unidecode(string.strip().lower())\n",
    "    string=string.replace('-',' ')\n",
    "    string=string.replace('\\'', \" \")\n",
    "    return re.sub(' +', ' ', string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inclusivité entre les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_inclusivity(df_join, df_right, col_left, col_right, other_col_left, other_col_right):\n",
    "    #Copy of the df_join:\n",
    "    df_join_copy=df_join.copy()\n",
    "    columns_to_update=df_right.columns\n",
    "    #Loop over the nans elements: \n",
    "    for index_na, element_na in df_join[df_join[columns_to_update[1]].isna()].iterrows():\n",
    "        for index_right, element_right in df_right.iterrows():\n",
    "            #If condition\n",
    "            if (((element_na[col_left] in element_right[col_right])\n",
    "            or (element_right[col_right] in element_na[col_left]))\n",
    "                \n",
    "            and ((element_na[other_col_left] in element_right[other_col_right])\n",
    "            or (element_right[other_col_right] in element_na[other_col_left]))):\n",
    "                \n",
    "                #Updating columns:\n",
    "                for col_up in columns_to_update:\n",
    "                    df_join_copy[col_up].iloc[index_na]=element_right[col_up]\n",
    "                    \n",
    "    return df_join_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodes avec TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Première méthode: Une seule colonne dans la comparaison au sens de TF-IDF et cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_return_answers(df_missing_left, df_right, column_left,\n",
    "                        column_right, other_column_left, other_column_right, top_n=5):\n",
    "    \"\"\"\n",
    "    This function, from one dataset with nans, and the other to be associated with the first one, \n",
    "    returns a new dataFrame with what has been found\n",
    "    \n",
    "    @Inputs:\n",
    "    -df_missing_left\n",
    "    -df_right\n",
    "    -column_left\n",
    "    -column_right\n",
    "    -Other_column_left\n",
    "    -Other_column_right\n",
    "    -top_n, int, optional,the number of top_n answers to be retreived\n",
    "    @Outputs:\n",
    "    -df_new_values\n",
    "    \"\"\"\n",
    "    #Initializing a tfidf model:\n",
    "    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=0, norm='l2', encoding='latin-1', ngram_range=(1,1))\n",
    "    #Applying the new tfidf model on the right Dataframe and on the column specified:\n",
    "    tfidf_matrix_right = tfidf.fit_transform(df_right[column_right]).toarray()\n",
    "    #Creating the DataFrame this function is going to be returning:\n",
    "    #Firstly, this DataFrame countains only the uncomplete rows:\n",
    "    df_new_values=df_missing_left.copy()\n",
    "    #We add the sim_score column to save the similarity scores:\n",
    "    df_new_values['sim_score']=0\n",
    "    #Loop over the indexes and elements in the new DataFrame:\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Modifying this line:\n",
    "    for index,element in df_new_values[df_new_values[column_right].isna()].iterrows():\n",
    "        #Defining the query for each row:\n",
    "        query=element[column_left]\n",
    "        #Transforming the query from the tfidf_model:\n",
    "        tfidf_query=tfidf.transform([query]).toarray()\n",
    "        #Calculating the cosine similarities between the query and the tfidf_matrix_right\n",
    "        cosine_similarities = cosine_similarity(tfidf_query,tfidf_matrix_right).flatten()\n",
    "        #We sort the documents from the similarity to the query :\n",
    "        related_docs_indices = [i for i in cosine_similarities.argsort()[::-1]]\n",
    "        #We retrieve the top n documents most similar to the given query :\n",
    "        indexes_scores = [(index_t, cosine_similarities[index]) for index_t in related_docs_indices][0:top_n]\n",
    "        #Loop over the index and scores of the answers:\n",
    "        for index_ans, score_ans in indexes_scores:\n",
    "            #Verifying over the other column:\n",
    "            if ((element[other_column_left] in df_right.iloc[index_ans][other_column_right])\n",
    "                or \n",
    "                (df_right.iloc[index_ans][other_column_right] in element[other_column_left])):\n",
    "                \n",
    "        \n",
    "                \n",
    "                #This answer is then satisfying our conditions, so we can merge the two rows.                \n",
    "                df_new_values.loc[index]=df_new_values.loc[index].fillna(df_right.iloc[index_ans])\n",
    "                #We add, for information, the score:\n",
    "                df_new_values.loc[index,'sim_score']=score_ans\n",
    "                #We break the loop since we found an answer:\n",
    "                break\n",
    "    return df_new_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seconde méthode: Plusieurs colonnes dans la comparaison au sens de TF-IDF et de cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_return_answers_deux(df_missing_left, df_right, column_left,\n",
    "                        column_right, other_column_left, other_column_right, top_n=5):\n",
    "    \"\"\"\n",
    "    This function, from one dataset with nans, and the other to be associated with the first one, \n",
    "    returns a new dataFrame with what has been found\n",
    "    \n",
    "    @Inputs:\n",
    "    -df_missing_left\n",
    "    -df_right\n",
    "    -column_left\n",
    "    -column_right\n",
    "    -Other_column_left\n",
    "    -Other_column_right\n",
    "    -top_n, int, optional,the number of top_n answers to be retreived\n",
    "    @Outputs:\n",
    "    -df_new_values\n",
    "    \"\"\"\n",
    "    #Initializing a tfidf model:\n",
    "    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=0, norm='l2', encoding='latin-1', ngram_range=(1,1))\n",
    "    #Applying the new tfidf model on the right Dataframe and on the column specified:\n",
    "    tfidf_matrix_right = tfidf.fit_transform(df_right[column_right].str.cat(df_right[other_column_right].values.astype(str), sep=' ').astype(str)).toarray()\n",
    "    #Creating the DataFrame this function is going to be returning:\n",
    "    #Firstly, this DataFrame countains only the uncomplete rows:\n",
    "    df_new_values=df_missing_left.copy()\n",
    "    #We add a column representing the similarity score:\n",
    "    df_new_values['sim_score']=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Modifying this line:\n",
    "    #Loop over the indexes and elements in the new DataFrame:\n",
    "    for index,element in df_new_values[df_new_values[column_right].isna()].iterrows():\n",
    "        #Defining the query for each row:\n",
    "        query=element[column_left]+' '+element[other_column_left]\n",
    "        #Transforming the query from the tfidf_model:\n",
    "        tfidf_query=tfidf.transform([query]).toarray()\n",
    "        #Calculating the cosine similarities between the query and the tfidf_matrix_right\n",
    "        cosine_similarities = cosine_similarity(tfidf_query,tfidf_matrix_right).flatten()\n",
    "        #We sort the documents from the similarity to the query :\n",
    "        related_docs_indices = [i for i in cosine_similarities.argsort()[::-1]]\n",
    "        #We retrieve the top n documents most similar to the given query :\n",
    "        indexes_scores = [(index_t, cosine_similarities[index]) for index_t in related_docs_indices][0:top_n]\n",
    "        #Loop over the index and scores of the answers:\n",
    "        for index_ans, score_ans in indexes_scores:\n",
    "            #Verifying over the other column:\n",
    "            if ((element[other_column_left] in df_right.iloc[index_ans][other_column_right]) \n",
    "                or \n",
    "                (df_right.iloc[index_ans][other_column_right] in element[other_column_left])):\n",
    "                \n",
    "                #This answer is then satisfying our conditions, so we can merge the two rows.                \n",
    "                df_new_values.loc[index]=df_new_values.loc[index].fillna(df_right.iloc[index_ans])\n",
    "                #We add, for information, the score:\n",
    "                df_new_values.loc[index,'sim_score']=score_ans\n",
    "                #We break the loop since we found an answer:\n",
    "                break\n",
    "                \n",
    "    return df_new_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'affichage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction, `print_step_results`, permet l'affichage des résultats après chaque étape réalisée dans la fonction. \n",
    "\n",
    "Cela permet de ne pas surcharger la fonction finale, puisqu'un code similaire sera exécuté à chaque fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_steps_results(df,one_col_right,step_name):\n",
    "    print(\"------------------\", step_name, \"-------------------\")\n",
    "    number_rows=df.shape[0]\n",
    "    number_to_find=df[one_col_right].isna().sum()\n",
    "    number_found=number_rows-number_to_find\n",
    "    print(\"Au début de cette étape, il y avait {n_rows} éléments à trouver.\\n\\\n",
    "    Appliquer cette étape a permis de trouver {n_found} éléments supplémentaires.\\n\"\\\n",
    "          .format(n_rows=number_rows,n_found=number_found))\n",
    "    print('Il reste maintenant {n_to_find} éléments à trouver.'.format(n_to_find=number_to_find))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'interactions avec l'utilisateur:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction, `func_interact`, permet d'intéragir avec l'utilisateur, pour lui permettre de modifier les résultats si certains ne lui semblent pas être les bons. \n",
    "\n",
    "Il peut alors, en spécifiant le nom de la colonne pour laquelle il veut préciser les éléments à supprimer, et en entrant ces éléments, de les supprimer dans le DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_interact(df, columns_right):\n",
    "    #Initializing the answers:\n",
    "    ans_mistake=\" \"\n",
    "    col=\" \"\n",
    "    #Copying the Dataframe in input:\n",
    "    df_copy=df.copy()\n",
    "    \n",
    "    while ans_mistake != \"o\" or ans_mistake != \"n\":\n",
    "        #Asking the user if he notices any mistakes:\n",
    "        print('Voyez vous des erreurs ? O ou N ?')\n",
    "        ans_mistake=input().strip().lower()\n",
    "        if ans_mistake=='o':\n",
    "            while col not in df_copy.columns:\n",
    "                print('Pour quelle colonne voulez vous entrer les valeurs EXACTES?')\n",
    "                col=input()\n",
    "                if col not in df_copy.columns:\n",
    "                    print(\"Le nom de colonne n'est pas exact. Merci de répondre à nouveau.\")\n",
    "            print(\"Quelles sont les valeurs que vous voulez supprimer ? \")\n",
    "            List_element=input()\n",
    "            #Transformation de la string de la liste en une liste:\n",
    "            List_element=ast.literal_eval(List_element)\n",
    "            #Loop over the elements inside the list:\n",
    "            for el in List_element:\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #Replacing by nans the unsatisfying results:\n",
    "                df_copy.loc[df_copy[col]==el, 'columns_right'] = np.nan\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        elif ans_mistake=='n':\n",
    "            print(\"Content qu'il n'y ait plus d'erreurs !\")\n",
    "        else:\n",
    "            print(\"Votre réponse n'est ni 'O' ni 'N', merci de répondre à nouveau.\")\n",
    "            \n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place de la fonction globale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs étapes sont ici à considérer:\n",
    "1. **Nettoyer les champs des colonnes**\n",
    "\n",
    "\n",
    "2. **Appliquer une première jointure, avec égalité parfaite après le nettoyage de la précédente étape**\n",
    "    1. Afficher les résultats \n",
    "    \n",
    "    \n",
    "3. **Appliquer une jointure en testant l'inclusivité**\n",
    "    1. Afficher les résultats\n",
    "    \n",
    "    \n",
    "4. **Appliquer la première méthode avec TF-IDF**\n",
    "    1. Afficher les résultats\n",
    "    2. Afficher les éléments trouvés *en plus* par rapport à l'étape précéddente\n",
    "    \n",
    "    \n",
    "5. **Appliquer la deuxième méthode avec TF-IDF**\n",
    "    1. Afficher les résultats\n",
    "    2. Afficher les éléments trouvés *en plus* par rapport à l'étape précédente\n",
    "    \n",
    "    \n",
    "6. **Demander quels résultats ne semblent pas satisfaisants**\n",
    "\n",
    "\n",
    "7. **Afficher tous les résultats**\n",
    "\n",
    "\n",
    "8. **Demander si certains résultats semblent à supprimer à nouveau**\n",
    "\n",
    "La fonction, nommé `merging_two_datasets`, est développée ci-après:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_two_datasets(df_left, df_right, columns_left, columns_right, interact=False):\n",
    "    \"\"\"\n",
    "    Function merging_two_datasets, taking the \n",
    "    @Inputs:\n",
    "    -df_left\n",
    "    \n",
    "    -df_right\n",
    "    \n",
    "    \n",
    "    -columns_left\n",
    "    The id of the df_left dataframe MUST BE the first element of this list\n",
    "    \n",
    "    \n",
    "    -columns_right\n",
    "    \n",
    "    -interact, boolean,\n",
    "    @Outputs:\n",
    "    -df_merged\n",
    "    \"\"\"\n",
    "    #We take the name of the id column for both DataFrame\n",
    "    col_id_left=columns_left[0]\n",
    "    col_id_right=columns_right[0]\n",
    "    \n",
    "    #Verifying there is one Id per row and that the number of Ids is equal to the number of rows:\n",
    "    #We also make a copy of the input Dataframe to avoid modifying them by mistake\n",
    "    df_left_travail=df_left.groupby(col_id_left).first().reset_index()[columns_left].copy()\n",
    "    df_right_travail=df_right.groupby(col_id_right).first().reset_index()[columns_right].copy()\n",
    "    #Cleaning the datasets:\n",
    "    for col_left in columns_left[1:]:\n",
    "        df_left_travail[col_left]=df_left_travail[col_left].astype(str).apply(format_string)\n",
    "    for col_right in columns_right[1:]:\n",
    "        df_right_travail[col_right]=df_right_travail[col_right].astype(str).apply(format_string)    \n",
    "    #Trying the first merge, just by cleaning the Dataframes:\n",
    "    df_first_left_merge=pd.merge(left=df_left_travail,\n",
    "                           right=df_right_travail,\n",
    "                           left_on=columns_left[1:],\n",
    "                           right_on=columns_right[1:],\n",
    "                           how='left')\n",
    "    #Printing the results:\n",
    "    print_steps_results(df=df_first_left_merge,\n",
    "                        one_col_right=columns_right[1],\n",
    "                        step_name=\"Première étape : merge simple après nettoyage des données\")\n",
    "    \n",
    "    \n",
    "    #Trying the second merge, dealing with inclusivity:\n",
    "    df_inclusivity_left_merge=merge_inclusivity(df_join=df_first_left_merge, \n",
    "                                                df_right=df_right_travail, \n",
    "                                                col_left=columns_left[1], \n",
    "                                                col_right=columns_right[1], \n",
    "                                                other_col_left=columns_left[2], \n",
    "                                                other_col_right=columns_right[2])\n",
    "    #Printing the results:\n",
    "    print_steps_results(df=df_inclusivity_left_merge,\n",
    "                        one_col_right=columns_right[1],\n",
    "                        step_name=\"Seconde étape : merge avec inclusion après nettoyage des données\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #First method with TFIDF:\n",
    "    df_first_tfidf_merge=find_return_answers(df_missing_left=df_inclusivity_left_merge, \n",
    "                                             df_right=df_right_travail, \n",
    "                                             column_left=columns_left[1],\n",
    "                                             column_right=columns_right[1], \n",
    "                                             other_column_left=columns_left[2], \n",
    "                                             other_column_right=columns_right[2], \n",
    "                                             top_n=5)\n",
    "    \n",
    "\n",
    "    #Printing the results:\n",
    "    print_steps_results(df=df_first_tfidf_merge,\n",
    "                        one_col_right=columns_right[1],\n",
    "                        step_name=\"Première étape de TFIDF\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    #Second method with TFIDF:\n",
    "    df_second_tfidf_merge=find_return_answers_deux(df_missing_left=df_first_tfidf_merge, \n",
    "                                                   df_right=df_right_travail, \n",
    "                                                   column_left=columns_left[1],\n",
    "                                                   column_right=columns_right[1], \n",
    "                                                   other_column_left=columns_left[2], \n",
    "                                                   other_column_right=columns_right[2], \n",
    "                                                   top_n=5)\n",
    "    #Printing the results:\n",
    "    print_steps_results(df=df_second_tfidf_merge,\n",
    "                        one_col_right=columns_right[1],\n",
    "                        step_name=\"Seconde étape de TFIDF\")\n",
    "    \n",
    "    \n",
    "    return df_second_tfidf_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application et test de la fonction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base des fréquentations:\n",
    "df_freq=pd.read_csv('data_clean/df_freq_clean.csv')\n",
    "#Base Muséofile:\n",
    "df_museofile=pd.read_csv('data_clean/df_geo_museofile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REF_DU_MUSEE</th>\n",
       "      <th>REGION</th>\n",
       "      <th>NOM_DU_MUSEE</th>\n",
       "      <th>VILLE</th>\n",
       "      <th>Type_de_fréquentation</th>\n",
       "      <th>Année</th>\n",
       "      <th>Entrées</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7511701</td>\n",
       "      <td>ÎLE-DE-France</td>\n",
       "      <td>Musée National Jean-Jacques Henner</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>Payante</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7511701</td>\n",
       "      <td>ÎLE-DE-France</td>\n",
       "      <td>Musée National Jean-Jacques Henner</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>Payante</td>\n",
       "      <td>2002</td>\n",
       "      <td>803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7511701</td>\n",
       "      <td>ÎLE-DE-France</td>\n",
       "      <td>Musée National Jean-Jacques Henner</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>Payante</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7511701</td>\n",
       "      <td>ÎLE-DE-France</td>\n",
       "      <td>Musée National Jean-Jacques Henner</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>Payante</td>\n",
       "      <td>2010</td>\n",
       "      <td>8729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7511801</td>\n",
       "      <td>ÎLE-DE-France</td>\n",
       "      <td>Musée de Montmartre</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>Payante</td>\n",
       "      <td>2009</td>\n",
       "      <td>50541.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REF_DU_MUSEE         REGION                        NOM_DU_MUSEE  VILLE  \\\n",
       "0      7511701  ÎLE-DE-France  Musée National Jean-Jacques Henner  PARIS   \n",
       "1      7511701  ÎLE-DE-France  Musée National Jean-Jacques Henner  PARIS   \n",
       "2      7511701  ÎLE-DE-France  Musée National Jean-Jacques Henner  PARIS   \n",
       "3      7511701  ÎLE-DE-France  Musée National Jean-Jacques Henner  PARIS   \n",
       "4      7511801  ÎLE-DE-France                 Musée de Montmartre  PARIS   \n",
       "\n",
       "  Type_de_fréquentation  Année  Entrées  \n",
       "0               Payante   2008      0.0  \n",
       "1               Payante   2002    803.0  \n",
       "2               Payante   2004      0.0  \n",
       "3               Payante   2010   8729.0  \n",
       "4               Payante   2009  50541.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifiant</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Artiste</th>\n",
       "      <th>Atout</th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>Code_Postal</th>\n",
       "      <th>Domaine_thématique</th>\n",
       "      <th>Département</th>\n",
       "      <th>Date_de_saisie</th>\n",
       "      <th>Histoire</th>\n",
       "      <th>...</th>\n",
       "      <th>Région</th>\n",
       "      <th>Téléphone</th>\n",
       "      <th>Thèmes</th>\n",
       "      <th>URL</th>\n",
       "      <th>Ville</th>\n",
       "      <th>geolocalisation</th>\n",
       "      <th>coord_x</th>\n",
       "      <th>coord_y</th>\n",
       "      <th>merc_x</th>\n",
       "      <th>merc_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0410</td>\n",
       "      <td>Parc de Bécon, 178 Boulevard Saint Denis</td>\n",
       "      <td>Ary Scheffer, René Ménard, Fernand Roybet, Car...</td>\n",
       "      <td>Situé dans le parc de Bécon dont l’origine rem...</td>\n",
       "      <td>Maison d'artiste</td>\n",
       "      <td>92400</td>\n",
       "      <td>Arts décoratifs;Art moderne et contemporain;Be...</td>\n",
       "      <td>Hauts-de-Seine</td>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>Les collections furent constituées au départ p...</td>\n",
       "      <td>...</td>\n",
       "      <td>Ile-de-France</td>\n",
       "      <td>01 71 05 77 92</td>\n",
       "      <td>Beaux-Arts : Dessin, Estampe et Affiche, Peint...</td>\n",
       "      <td>http://www.museeroybetfould.fr</td>\n",
       "      <td>Courbevoie</td>\n",
       "      <td>48.900998,2.271279</td>\n",
       "      <td>48.900998</td>\n",
       "      <td>2.271279</td>\n",
       "      <td>252837.621729</td>\n",
       "      <td>6.258079e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M5076</td>\n",
       "      <td>Place Monsenergue</td>\n",
       "      <td>Joseph Vernet, Pascal de La Rose, Morel-Fatio,...</td>\n",
       "      <td>Conservatoire de l'histoire de l'arsenal et du...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83000</td>\n",
       "      <td>Histoire</td>\n",
       "      <td>Var</td>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>Créé à la fin du Premier Empire et ouvert au p...</td>\n",
       "      <td>...</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>04 94 02 02 01</td>\n",
       "      <td>Archéologie nationale : Gallo-romain, Moderne;...</td>\n",
       "      <td>http://www.musee-marine.fr</td>\n",
       "      <td>Toulon</td>\n",
       "      <td>43.122018,5.929368</td>\n",
       "      <td>43.122018</td>\n",
       "      <td>5.929368</td>\n",
       "      <td>660054.226486</td>\n",
       "      <td>5.330563e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Identifiant                                   Adresse  \\\n",
       "0       M0410  Parc de Bécon, 178 Boulevard Saint Denis   \n",
       "1       M5076                         Place Monsenergue   \n",
       "\n",
       "                                             Artiste  \\\n",
       "0  Ary Scheffer, René Ménard, Fernand Roybet, Car...   \n",
       "1  Joseph Vernet, Pascal de La Rose, Morel-Fatio,...   \n",
       "\n",
       "                                               Atout         Catégorie  \\\n",
       "0  Situé dans le parc de Bécon dont l’origine rem...  Maison d'artiste   \n",
       "1  Conservatoire de l'histoire de l'arsenal et du...               NaN   \n",
       "\n",
       "   Code_Postal                                 Domaine_thématique  \\\n",
       "0        92400  Arts décoratifs;Art moderne et contemporain;Be...   \n",
       "1        83000                                           Histoire   \n",
       "\n",
       "      Département Date_de_saisie  \\\n",
       "0  Hauts-de-Seine     2019-01-21   \n",
       "1             Var     2019-01-21   \n",
       "\n",
       "                                            Histoire  ...  \\\n",
       "0  Les collections furent constituées au départ p...  ...   \n",
       "1  Créé à la fin du Premier Empire et ouvert au p...  ...   \n",
       "\n",
       "                       Région       Téléphone  \\\n",
       "0               Ile-de-France  01 71 05 77 92   \n",
       "1  Provence-Alpes-Côte d'Azur  04 94 02 02 01   \n",
       "\n",
       "                                              Thèmes  \\\n",
       "0  Beaux-Arts : Dessin, Estampe et Affiche, Peint...   \n",
       "1  Archéologie nationale : Gallo-romain, Moderne;...   \n",
       "\n",
       "                              URL       Ville     geolocalisation    coord_x  \\\n",
       "0  http://www.museeroybetfould.fr  Courbevoie  48.900998,2.271279  48.900998   \n",
       "1      http://www.musee-marine.fr      Toulon  43.122018,5.929368  43.122018   \n",
       "\n",
       "    coord_y         merc_x        merc_y  \n",
       "0  2.271279  252837.621729  6.258079e+06  \n",
       "1  5.929368  660054.226486  5.330563e+06  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_museofile.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'avons plus qu'à spécifier les arguments de a fonction : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left=df_museofile\n",
    "df_right=df_freq\n",
    "columns_left=['Identifiant', 'Nom_officiel', 'Ville']\n",
    "columns_right=['REF_DU_MUSEE', 'NOM_DU_MUSEE', 'VILLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis la lancer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Première étape : merge simple après nettoyage des données -------------------\n",
      "Au début de cette étape, il y avait 1114 éléments à trouver.\n",
      "    Appliquer cette étape a permis de trouver 664 éléments supplémentaires.\n",
      "\n",
      "Il reste maintenant 450 éléments à trouver.\n",
      "------------------ Seconde étape : merge avec inclusion après nettoyage des données -------------------\n",
      "Au début de cette étape, il y avait 1114 éléments à trouver.\n",
      "    Appliquer cette étape a permis de trouver 857 éléments supplémentaires.\n",
      "\n",
      "Il reste maintenant 257 éléments à trouver.\n",
      "------------------ Première étape de TFIDF -------------------\n",
      "Au début de cette étape, il y avait 1114 éléments à trouver.\n",
      "    Appliquer cette étape a permis de trouver 1025 éléments supplémentaires.\n",
      "\n",
      "Il reste maintenant 89 éléments à trouver.\n",
      "------------------ Seconde étape de TFIDF -------------------\n",
      "Au début de cette étape, il y avait 1114 éléments à trouver.\n",
      "    Appliquer cette étape a permis de trouver 1089 éléments supplémentaires.\n",
      "\n",
      "Il reste maintenant 25 éléments à trouver.\n"
     ]
    }
   ],
   "source": [
    "df_results=merging_two_datasets(df_left, df_right, columns_left, columns_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont alors ici stockés dans `df_results`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons pu voir que la fonction renvoie un affichage en temps réel (i.e. en même temps que l'execution de la fonction) des résultats. \n",
    "\n",
    "Les résultats sont les mêmes que lorsque j'ai développé les fonctions sans que ce soit automatique, ce qui est logique.\n",
    "\n",
    "Vous pouvez d'ailleurs trouver ce notebook de développement [ici](https://github.com/adrihans/musees_de_france_app/blob/master/Linking_datasets.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temps nécessaire ici à l'éxécution de la fonction (sans interractions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Première étape : merge simple après nettoyage des données -------------------\n",
      "Au début de cette étape, il y avait 1114 éléments à trouver.\n",
      "    Appliquer cette étape a permis de trouver 664 éléments supplémentaires.\n",
      "\n",
      "Il reste maintenant 450 éléments à trouver.\n",
      "------------------ Seconde étape : merge avec inclusion après nettoyage des données -------------------\n",
      "Au début de cette étape, il y avait 1114 éléments à trouver.\n",
      "    Appliquer cette étape a permis de trouver 857 éléments supplémentaires.\n",
      "\n",
      "Il reste maintenant 257 éléments à trouver.\n",
      "------------------ Première étape de TFIDF -------------------\n",
      "Au début de cette étape, il y avait 1114 éléments à trouver.\n",
      "    Appliquer cette étape a permis de trouver 1025 éléments supplémentaires.\n",
      "\n",
      "Il reste maintenant 89 éléments à trouver.\n",
      "------------------ Seconde étape de TFIDF -------------------\n",
      "Au début de cette étape, il y avait 1114 éléments à trouver.\n",
      "    Appliquer cette étape a permis de trouver 1089 éléments supplémentaires.\n",
      "\n",
      "Il reste maintenant 25 éléments à trouver.\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%time df_results=merging_two_datasets(df_left, df_right, columns_left, columns_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ainsi développée a permis, dans cet exemple fleuve concernant la base Muséofile, de traiter les **1114** lignes en **2 min 25 s**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essai de la fonction avec interractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapes possibles après l'utilisation de la fonction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après l'utilisation de la fonction, on peut extraire un DataFrame avec seulement deux colonnes, c'est à dire les identifiants respectifs des deux Dataframes de départ, afin de pouvoir relier les deux datasets de base via ce dataframe *'de jonction'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col_left='Identifiant'\n",
    "id_col_right='REF_DU_MUSEE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jonction_freq_museofile=df_results[[id_col_left,id_col_right]].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifiant</th>\n",
       "      <th>REF_DU_MUSEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0001</td>\n",
       "      <td>6702101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0002</td>\n",
       "      <td>6733901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0003</td>\n",
       "      <td>6706101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M0004</td>\n",
       "      <td>6718002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M0005</td>\n",
       "      <td>6718001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Identifiant REF_DU_MUSEE\n",
       "0       M0001      6702101\n",
       "1       M0002      6733901\n",
       "2       M0003      6706101\n",
       "3       M0004      6718002\n",
       "4       M0005      6718001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jonction_freq_museofile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant enregistrer ce DataFrame de jonction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jonction_freq_museofile.to_csv('data_clean/df_jonction_freq_museofile.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation de ce notebook, et plus précisement de la fonction globale définie et testée, permet très facilement de définir les relations entre deux datasets. \n",
    "\n",
    "En effet, la jonction peut alors s'établir en précisant seulement: \n",
    "- Les deux jeux de données, sous format Pandas DataFrame\n",
    "- Les colonnes utiles \n",
    "\n",
    "\n",
    "Et on obtient un nouveau dataset permettant de faire la jonction entre les deux. \n",
    "\n",
    "\n",
    "Les réultats sont très satisfaisants, et même s'il y a des erreurs imputables à l'utilisation de méthodes plus évoluées comme TF-IDF, cela peut être résolu par l'utilisation des interactions permises par la fonction globale. \n",
    "\n",
    "De plus, les résultats s'établissent rapidement, avec un temps de 2min25s pour un DataFrame contenant 1114 lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REF_DU_MUSEE              0\n",
       "REGION                    0\n",
       "NOM_DU_MUSEE              0\n",
       "VILLE                     0\n",
       "Type_de_fréquentation     0\n",
       "Année                     0\n",
       "Entrées                  97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq['Entrées']=df_freq['Entrées'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq.to_csv('data_clean/df_freq_clean_without_nan.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59876 entries, 0 to 59875\n",
      "Data columns (total 7 columns):\n",
      "REF_DU_MUSEE             59876 non-null object\n",
      "REGION                   59876 non-null object\n",
      "NOM_DU_MUSEE             59876 non-null object\n",
      "VILLE                    59876 non-null object\n",
      "Type_de_fréquentation    59876 non-null object\n",
      "Année                    59876 non-null int64\n",
      "Entrées                  59876 non-null float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_freq.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
